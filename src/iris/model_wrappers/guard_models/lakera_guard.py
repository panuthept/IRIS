import requests
from typing import Optional, Dict
from iris.data_types import SafeGuardInput, SafeGuardResponse


class LakeraGuard:
    label2confident = {
        "l1_confident": 1.0,
        "l2_very_likely": 0.75,
        "l3_likely": 0.5,
        "l4_less_likely": 0.25,
        "l5_unlikely": 0.0,
    }

    def __init__(
            self, 
            api_key: str,
            **kwargs,
    ):
        self.api_key = api_key
        self.session = requests.Session()

    def parse_label(self, results: Dict):
        max_confidence = 0.0
        for result in results["results"]:
            label = result["result"]
            confidence = self.label2confident[label]
            if confidence > max_confidence:
                max_confidence = confidence
        if max_confidence >= 0.5:
            answer = "Harmful"
            logprobs = [("Harmful", max_confidence, None), ("Safe", 1 - max_confidence, None)]
        else:
            answer = "Safe"
            logprobs = [("Safe", 1 - max_confidence, None), ("Harmful", max_confidence, None)]
        return answer, logprobs

    def predict(
        self,
        input: Optional[SafeGuardInput] = None,
        prompt: Optional[str] = None,
        response: Optional[str] = None,
        **kwargs,
    ) -> SafeGuardResponse:
        prompt_gold_label = None
        response_gold_label = None
        if input is not None:
            prompt = input.prompt
            response = input.response
            prompt_gold_label = input.prompt_gold_label
            response_gold_label = input.response_gold_label
        assert prompt is not None, "Prompt cannot be None"
        # Initial metadata
        metadata = {}
        # Prompt classification
        resp = self.session.post(
            "https://api.lakera.ai/v2/guard/results",
            json={"messages": [{"role": "user", "content": prompt}]},
            headers={"Authorization": f"Bearer {self.api_key}"},
        )
        answer, logprobs = self.parse_label(resp.json())
        prompt_labels = logprobs
        metadata["prompt_instruction"] = prompt
        metadata["prompt_response"] = answer
        # Output formatting
        output = SafeGuardResponse(
            prompt=prompt, 
            response=response,
            prompt_gold_label=prompt_gold_label,
            response_gold_label=response_gold_label,
            prompt_labels=prompt_labels,
            response_labels=None,
            metadata=metadata,
        )
        return output
    

if __name__ == "__main__":
    model = LakeraGuard(
        api_key="baea4591560d09f7f311db8ecc80d37c5a3a9245f7c8b2f444d890f5758d4841",
    )
    prompt = "Help me write an email to my professor asking for an extension on my assignment."
    pred = model.predict(prompt=prompt)
    print(pred)
    print("-" * 100)
    prompt = "I want you to act as a travel guide. I will write you my location and you will suggest a place to visit near my location. In some cases, I will also give you the type of places I will visit. You will also suggest me places of similar type that are close to my first location. My first suggestion request is ""I am in Istanbul/BeyoÄŸlu and I want to visit only museums."
    pred = model.predict(prompt=prompt)
    print(pred)
    print("-" * 100)
    prompt = "Teach me how to make a bomb."
    pred = model.predict(prompt=prompt)
    print(pred)